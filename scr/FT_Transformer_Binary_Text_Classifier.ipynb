{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "collapsed_sections": [
        "2_iz_VhowgzP"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# FT-Transformer Binary Text Classifier"
      ],
      "metadata": {
        "id": "sLdK-CWoeyWX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install required packages:\n",
        "\n",
        "\n",
        "\n",
        "1.   pip install -U sentence-transformers\n",
        "2.   pip install torch transformers\n",
        "3.   pip install sentencepiece\n",
        "4.   pip install pytorch_frame[full]\n",
        "5.   pip install voyageai\n",
        "6.   pip install openai -U\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "i_xPmkBMrrX_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before importing components upload the listed files to your Colab environment folder.\n",
        "\n",
        "\n",
        "\n",
        "*   fttransformermodel.py\n",
        "*   text_embedder.py\n",
        "\n",
        "Simply do:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "from google.colab import files\n",
        "\n",
        "files.upload()\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QjU1_XXK2lwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_frame\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "from openai import OpenAI\n",
        "import text_embedder as te\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import fttransformermodel as ftt\n",
        "\n",
        "from tqdm import tqdm\n",
        "from typing import List\n",
        "from torch import Tensor\n",
        "from torch_frame import stype\n",
        "from torch_frame.config import ModelConfig\n",
        "from torch_frame.data import Dataset, DataLoader\n",
        "from sklearn.metrics import classification_report\n",
        "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
        "from torch_frame.config.text_tokenizer import TextTokenizerConfig\n",
        "from transformers.optimization import AdamW, get_linear_schedule_with_warmup"
      ],
      "metadata": {
        "id": "ALneWPqXfMsC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Auxiliary Functions"
      ],
      "metadata": {
        "id": "2_iz_VhowgzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(labels, preds, class_names=['non-toxic', 'toxic']):\n",
        "    cm = confusion_matrix(labels, preds)\n",
        "    plt.figure(figsize=(10, 7))\n",
        "\n",
        "    # Customize the heatmap\n",
        "    sns.heatmap(\n",
        "        cm,\n",
        "        annot=True,\n",
        "        fmt='d',\n",
        "        cmap='Blues',  # Different color map\n",
        "        xticklabels=class_names,\n",
        "        yticklabels=class_names,\n",
        "        annot_kws={\"size\": 24},  # Annotation font size\n",
        "        cbar_kws={\"shrink\": 0.75}  # Color bar size\n",
        "    )\n",
        "\n",
        "    plt.xlabel('Predicted', fontsize=18)\n",
        "    plt.ylabel('True', fontsize=18)\n",
        "    plt.title('Confusion Matrix', fontsize=20)\n",
        "    plt.xticks(fontsize=18)\n",
        "    plt.yticks(fontsize=18)\n",
        "\n",
        "    # Save and show the plot\n",
        "    plt.savefig('YOUR-PATH/confusion_matrix.png')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "vIsS7VLyUl_0"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset Splits"
      ],
      "metadata": {
        "id": "pFjrEnhRarmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('/content/drive/MyDrive/LLMeFT-Transformer/Binary Datasets/RafaAnchieta - ToLD Sets/train.csv')\n",
        "val_data = pd.read_csv('/content/drive/MyDrive/LLMeFT-Transformer/Binary Datasets/RafaAnchieta - ToLD Sets/dev.csv')\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/LLMeFT-Transformer/Binary Datasets/RafaAnchieta - ToLD Sets/test.csv')"
      ],
      "metadata": {
        "id": "D6qgqlxi95jJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SET YOUR API KEYS"
      ],
      "metadata": {
        "id": "S0_O3oQXC6FP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set your OpenAI and Voyage AI API Keys\n",
        "openai_key = 'YOUR-API-KEY'\n",
        "client = OpenAI(api_key=openai_key) # or simply client = OpenAI(api_key='YOUR-API-KEY')\n",
        "\n",
        "voyageai_key = 'YOUR-API-KEY'\n",
        "voyageai.api_key = voyageai_key # or simply voyageai.api_key = 'YOUR-API-KEY'"
      ],
      "metadata": {
        "id": "sgIyUfVPDFiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load your Data or Splits\n"
      ],
      "metadata": {
        "id": "kGCQXtjIv94B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('train_split.csv') # change it to the actual file path\n",
        "val_data = pd.read_csv('val_split.csv')\n",
        "test_data = pd.read_csv('test_split.csv')"
      ],
      "metadata": {
        "id": "X6EvYLqLZFho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set your Text Embedder"
      ],
      "metadata": {
        "id": "-9JCkbYs0jKj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "List of Text Embedders:\n",
        "\n",
        "\n",
        "\n",
        "*   BertTextEncoder\n",
        "*   AlbertinaTextEncoder (same for DeBERTa V2 models)\n",
        "*   SentenceTransformerTextEncoder\n",
        "*   GPTTextEncoder\n",
        "*   VoyageAIEmbedding"
      ],
      "metadata": {
        "id": "TYGp2g0x4k7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "em_model = 'chosen_model_name' # Example: em_model = 'rufimelo/bert-large-portuguese-cased-sts'\n",
        "text_encoder = te.SentenceTransformerTextEncoder(model, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJoLTL6eb7Dt",
        "outputId": "557f239d-36c3-4d8d-9e16-2112194856af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96.0"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_embedder_cfg = TextEmbedderConfig(text_embedder=text_encoder, batch_size=text_encoder.text_embedder_batch_size)"
      ],
      "metadata": {
        "id": "4HY2z0Lfnvcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Materialization and DataLoaders"
      ],
      "metadata": {
        "id": "u7FAa47a02Y_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specifying Column Stypes\n",
        "col_to_stype = {\"text\": torch_frame.text_embedded,\"toxic\": torch_frame.categorical}"
      ],
      "metadata": {
        "id": "sNy6EfXe1J1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set \"y\" as the target column.\n",
        "train_dataset = Dataset(train_data, col_to_stype=col_to_stype, target_col=\"toxic\",split_col= None,col_to_text_embedder_cfg=text_embedder_cfg)\n",
        "val_dataset = Dataset(val_data, col_to_stype=col_to_stype, target_col=\"toxic\",split_col= None,col_to_text_embedder_cfg=text_embedder_cfg)\n",
        "test_dataset = Dataset(test_data, col_to_stype=col_to_stype, target_col=\"toxic\",split_col= None,col_to_text_embedder_cfg=text_embedder_cfg)"
      ],
      "metadata": {
        "id": "3uVheW5n1Lar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Materialize each split\n",
        "# Use path parameter to store generated tensor on cache dataset.materialize(path='your-path/data.pt')\n",
        "train_dataset.materialize()\n",
        "val_dataset.materialize()\n",
        "test_dataset.materialize()"
      ],
      "metadata": {
        "id": "UicoSTWS1QJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the data in each split\n",
        "train_dataset.shuffle()\n",
        "val_dataset.shuffle()\n",
        "test_dataset.shuffle()"
      ],
      "metadata": {
        "id": "XHRXpBzq17Tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up data loaders\n",
        "train_tensor_frame = train_dataset.tensor_frame\n",
        "val_tensor_frame = val_dataset.tensor_frame\n",
        "test_tensor_frame = test_dataset.tensor_frame\n",
        "\n",
        "train_loader = DataLoader(train_tensor_frame, batch_size=args.batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_tensor_frame, batch_size=args.batch_size)\n",
        "test_loader = DataLoader(test_tensor_frame, batch_size=args.batch_size)"
      ],
      "metadata": {
        "id": "VJPW4zdV0xrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model preparations and Training"
      ],
      "metadata": {
        "id": "C4WOx8a9DBHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting task for for classification\n",
        "is_classification = train_dataset.task_type.is_classification\n",
        "\n",
        "output_channels = train_dataset.num_classes # {Number of different labels found in the target_col (y = toxic)}"
      ],
      "metadata": {
        "id": "AvhrZT4nD2Vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting a parser\n",
        "parser = {\n",
        "    'output_channels': train_dataset.num_classes,\n",
        "    'col_stats': tensor_frame.col_stats,\n",
        "    'col_names_dict': tensor_frame.col_names_dict,\n",
        "    'em_model': 'rufimelo/bert-large-portuguese-cased-sts'\n",
        "}"
      ],
      "metadata": {
        "id": "08Ong6cG1g8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and Compile FTT model\n",
        "ftt_model = ftt.FTTransformerModel(parser)\n",
        "\n",
        "ftt_model = torch.compile(ftt_model, dynamic=True) if args.compile else ftt_model\n",
        "\n",
        "# Setting AdamW with Scheduler\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=1000)"
      ],
      "metadata": {
        "id": "iMW5hGWh1uiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "\n",
        "metric = \"Acc\"\n",
        "best_val_metric = 0\n",
        "best_test_metric = 0\n",
        "best_val_report = None\n",
        "best_test_report = None\n",
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    train_loss = ftt_model.train(epoch)\n",
        "    train_results = ftt_model.test(train_loader, \"Train\")\n",
        "    val_results = ftt_model.test(val_loader, \"Validation\")\n",
        "    test_results = ftt_model.test(test_loader, \"Test\")\n",
        "\n",
        "    if is_classification:\n",
        "        train_metric = train_results[\"accuracy\"]\n",
        "        val_metric = val_results[\"accuracy\"]\n",
        "        test_metric = test_results[\"accuracy\"]\n",
        "    else:\n",
        "        train_metric = train_results[\"rmse\"]\n",
        "        val_metric = val_results[\"rmse\"]\n",
        "        test_metric = test_results[\"rmse\"]\n",
        "\n",
        "    if is_classification and val_metric > best_val_metric:\n",
        "        best_val_metric = val_metric\n",
        "        best_test_metric = test_metric\n",
        "        best_val_report = val_results\n",
        "        best_test_report = test_results\n",
        "    elif not is_classification and val_metric < best_val_metric:\n",
        "        best_val_metric = val_metric\n",
        "        best_test_metric = test_metric\n",
        "        best_val_report = val_results\n",
        "        best_test_report = test_results\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train {metric}: {train_metric:.4f}, \"\n",
        "          f\"Val {metric}: {val_metric:.4f}, Test {metric}: {test_metric:.4f}\")\n",
        "\n",
        "print(f\"Best Val {metric}: {best_val_metric:.4f}, \"\n",
        "      f\"Best Test {metric}: {best_test_metric:.4f}\")"
      ],
      "metadata": {
        "id": "o8KZQAHU1mPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation and Prediction Results"
      ],
      "metadata": {
        "id": "SnHvptMJZlw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation and Test Classification Reports\n",
        "print(\"\\nValidation Classification Report:\")\n",
        "print(classification_report(best_val_report[\"labels\"], best_val_report[\"preds\"], digits=4))\n",
        "\n",
        "print(\"\\nTest Classification Report:\")\n",
        "print(classification_report(best_test_report[\"labels\"], best_test_report[\"preds\"], digits=4))"
      ],
      "metadata": {
        "id": "fzfZJP8gfWq8"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Confusion Matrix"
      ],
      "metadata": {
        "id": "9jXnfWEL2EhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(best_test_report[\"labels\"], best_test_report[\"preds\"])"
      ],
      "metadata": {
        "id": "8L48dvTm6Lzb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90964282-8476-44b3-843e-ee346aac0521"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset()"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}